\documentclass[10pt]{article}

\usepackage{fancyvrb}
%% \usepackage{hyperref}

\title{Parallel and Distributed Programs\\
Lecture F12\\
24 February, 2014
}
\author{Joe Armstrong}

\fvset{frame=single,numbers=left,numbersep=3pt}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}
In this lecture we'll look at some ways of writing {\sl
  potentially parallel} programs.

In Erlang we write concurrent programs. The algorithms in the lecture
will run sequentially if run on a single core machine, but will run
in parallel if run on a multi-core computer. That's why they are
called ``potentially parallel.''


To make a parallel program either the programmer must say what is to be
done in parallel, or the system must discover this automatically.

Automatic parallelisation of programs has been studied for many years.
It is very good for certain classes of problem
and very bad for other classes of problem.

\subsection{GPU Parallism}

GPU = Graphics Programming Unit. All the computations are the same.

For example: To compute the temperature distribution over a conducting
surface we divide the surface into a grid and repeatedly average the
temperatures at the four corners of the squares surrounding each of
the points on the grid.
 
\begin{verbatim}

             | 
             X (i,j+1)
             |
             |
----X--------X-------X----
  (i-1,j)  (i,j)   (i+1,j)   
             |
             |
             X (i,j-1)
             |
             |

  T[k+1] = (T[k][i,j+1] + T[k][i-1,j] + 
            T[k][i+1,j] + T[k][i,j-1])/4
\end{verbatim}

Erlang is not suited for this.

\subsection{Embarrassing Parallelism}

The nature of the problem is naturally parallel and there are a lot of
things to be done.  There is little or no communication between the
tasks. The parallelism is obvious and inherent in the problem.

Example: A web server with millions of simultaneous connected users.
Erlang is very good at this.

\subsection{Declarative Parallelism}

Sometimes called ``functional parallelism''. In a pure functional
programming language \verb+f(g(...), h(...))+ \verb+g(...)+ and
\verb+h(...)+ can be evaluated in any order and in parallel.

Unfortunately, while this is true, it is still a research problem how
to map the computation onto the hardware we have {\sl today}, and {\sl
  hardware changes in time} so the solution we find today will not
work tomorrow.

There have been a large number of attempts to build parallel hardware to
do this. None have provided lasting solutions.

\section{Expressing Parallel Behaviour}

Different languages have syntactic constructs for expressing parallel
behavior, or can do this algorithmically.  This section reviews some
commonly used methods for expressing parallel behavior.

\subsection{ParBegin .. ParEnd}

\begin{verbatim}
ParBegin
   x;
   y;
   z;
ParEnd
\end{verbatim}

The above expression means evaluate \verb+x+, \verb+y+ and \verb+z+ in parallel. 

\verb+Fork+ ... \verb+Join+ is also used.

If shared memory is involved, simultaneous access to the shared memory must be
avoided. If no shared memory is involved the computations can proceed in parallel.

Both \verb+ParBegin+ .. \verb+ParEnd+ and \verb+Fork+ ... \verb+Join+ can be 
implemented using the lower level primitives \verb+promise+ and \verb+yield+.

\subsection{Promises}

A ``{\sl Promise}'' is a commitment to deliver a value in the future.

\begin{verbatim}
    P 
    |
    |  promise(F)  
T1  +------>-------+
    |              |
    |              | 
    |              |
    +------<-------+
    |
    |
T2  +
    |
\end{verbatim}

At some time \verb+T1+ a process \verb+P+ wants to compute \verb+F()+ so it calls
\verb+promise(F)+ which returns a tag \verb+Tag+. \verb+P+ continues,
and \verb+F()+ is computed in parallel. At some time later (\verb+T2+) when 
\verb+P+ wants the return value it calls \verb+yield(Tag)+. \verb+yield+ blocks until
the result of the computation is available.

Promises can be implmeneted in Erlang as follows:

\VerbatimInput{promises.erl}

\verb+promises:test1()+ blocks until the result is available:

\begin{Verbatim}
> promises:test1().
.... yawn .. 
...  shell is blocked ...
... I can't do anything ...
165580141
\end{Verbatim}

Using a promise we can do {\sl useful things} \textregistered{} while
the promised computation is being performed:

\begin{Verbatim}
2> Tag = promises:test2().
Ref<0.0.0.104>
3> promises:query(Tag).
not_finished
4> 213813813861736*128763816381638163.
27531482667950334890792863030968
5> promises:query(Tag).               
not_finished
6> 19379127391273971239719379173979372193137*18763861238183638.
363627257286948472579176034410575587459129627874409292406
7> promises:query(Tag).                                        
{finished,165580141}
\end{Verbatim}

{\sl Note: If a command fails in the shell, the promise will not
be honoured, the results will be send back to the old shell which has died!}

\subsection{Broken Promises}

What happens if \verb+P+ dies {\sl Before} the worker has computed
its response? Should the worker be killed?

What happens if the worker dies while computing F. Who should be told?
Who should be killed?

Distributed Computing is the art of repairing broken promises.

\subsection{Maps}

Here is a simple implement of \verb+smap+ (Sequential map) and
\verb+pmap+ (Parallel map).

\VerbatimInput{maps.erl}

In the non-failure case \verb+smap+ and \verb+pmap1+ behave
identically.

\begin{Verbatim}
1> Double = fun(X) -> 2*X end.
#Fun<erl_eval.6.71889879>
2> maps:smap(Double,[1,2,3,4]).
[2,4,6,8]
3> maps:pmap(Double,[1,2,3,4]). 
[2,4,6,8]
\end{Verbatim}

Now let's try and double the list \verb+[1,2,3,a,3,4,b]+. In the
failure case \verb+smap+ will fail on the first error (ie when
computing \verb+2*a+) but \verb+pmap+ will fail for every bad element in
the list.

\begin{Verbatim}
4> maps:smap(Double,[1,2,a,3,4,b]).
** exception error: an error occurred when evaluating an 
   arithmetic expression
     in operator  */2
        called as 2 * a
     in call from maps:'-smap/2-lc$^0/1-0-'/2 (maps.erl, line 5)
     in call from maps:'-smap/2-lc$^0/1-0-'/2 (maps.erl, line 5)
5> maps:pmap(Double,[1,2,a,3,4,b]).
[2,4,
 {'EXIT',{badarith,[{erlang,'*',[2,a],[]},
                    {maps,'-pmap/2-fun-0-',3,
                          [{file,"maps.erl"},{line,10}]}]}},
 6,8,
 {'EXIT',{badarith,[{erlang,'*',[2,b],[]},
                    {maps,'-pmap/2-fun-0-',3,
                          [{file,"maps.erl"},{line,10}]}]}}]

\end{Verbatim}

\subsection{Broken Maps}

The idea of \verb+pmap+ seems simple {\sl but it is not}.
Here are some of the problems that might occur.

\begin{description}

\item A computation in the map fails\\ 
Assume one of the computations of
\verb+F(I)+ fails. We could kill all the other computations. But
what happens if we don't really care if the computation failed? Many
of the earlier computations might have succeeded so why drop the
results? The computations might have taken a long time, it would be a  shame to
loose the results.

\item We have too much concurrency\\
\verb+pmap+ will be {\sl too parallel} if we have a list of 1M processes
and the function is {\sl Double} then pmapping the list would be wrong.
We'd create too many processes.

\item The overheads are too great\\
It might turn out that creating a parallel computation
costs more than just doing the sequential computation.

\end{description}

{\sl Discussion:} \verb+map+ and \verb+pmap+ have identical behavior
when there are no errors. In \verb+pmap+ we fail immediately on the
first error. In \verb+pmap+ we cannot easily fail on the first error.
(We could link all the parallel processes together, and let them all
die if any one dies)

\subsection{Map-Reduce}

Map-reduce is the name given to a method of parallelising
computations.  Note: The word ``map'' does not mean the same as the
word map used in functional programming. 

A full map-reduce framework provides the following:

\begin{itemize}

\item A way of starting a number of parallel computations.

\item A number of parallel proceses which perform computations. The map processes
  performs some computation and sends a stream of \verb+{Key,Value}+
  results to a reduce process.
  
\item A reduce process which merges values with the same Key.
\end{itemize}

For example: Calculating the frequency of words in a large set of
documents.  Assume the number of documents is \verb+K+.

Here's how we might do this in Erlang:

\begin{itemize}
\item We spawn a reducer process, Call this process \verb+Reducer+.
\item We spawn \verb+K+ parallel processes (workers) , and give each
  process the name of a file to work on, and the process identifier
  \verb+Reducer+.

\item Each worker analyses the data in the file it was given and sends
  a sequence of \verb+{Word,Count}+ pairs to the reducer process.
  For example, if the word ``tuple'' occurred ten times in a
  document it would send a \verb+{<<"tuple">>,10}+ tuple to the
  reduce process.

\item The reducer process merges the word count streams. So for
  example if it has received the tuples \verb+{<<"tuple">>,10}+ and
  \verb+{<<"tuple">>,15}+ it will know that the number of times the
  word has been seen is 25.

\end{itemize}

Several practical issues have to be dealt with when implementing
map-reduce:

\begin{itemize}

\item Termination. How do we know when the map phase has terminated.
  Should the reducer wait for all map processes to terminate before
  it terminates.

\item Bottlenecks. The reduce process could become a bottleneck. All
  the results eventually go to a single process. We might want to
  avoid this.
\end{itemize}

In practice we would probably limit the time for a map-reduce
operation to a fixed time, and build a tree of reducers. In the
word-count example we could build two reducers (one for words
beginning \verb+a..m+ and \verb+n..z+ or 26 reducer processes for
letters starting \verb+a+, \verb+b+ and so on.

\section{Components}

Parallel systems are often build from compents. Here are afew examples:

\subsection{Server}

A server has state. When it receives requests from a client, it
performs a computation which might update the state and then sends
a message back to the client.

(This is the server in the so call Client-Server Model)

\subsection{Publisher}

A publisher has a list of channels. \verb+[{Channel, [Pid1, Pid2, ...]}]+
The publisher accepts four input messages.

\begin{description}

\item \verb+{subscribe,Channel,Pid}+\\
  Adds \verb+Pid+ to the list
  of pids associated with \verb+ChannelName+. Creates a new channel if
  a channel does not exist.

\item \verb+{unsubscript_all,Pid}+\\
removes all subscriptions that Pid has.

\item \verb+{unsubscript_all,Channel, Pid}+\\
Remove the \verb+Pid+ to \verb+Channel+.
  
\item \verb+{publish,Channel,Msg}+\\ 
Sends Msg to all the subscribers associated with
\verb+Channel+. It is not an error to send a message to a channel with
zero subscribers.

\end{description}

Publisher has no errors.

A publisher is the PUB in the so called PUB-SUB model.

Note: PUB-SUB is an enormously important model: Twitter, Facebook,
Mailing Lists, IRC Newsletters are all variants on PUB-SUB

Actually PUB-SUB is a confusing term. It could mean the names of two
different processes. A Publisher Process that talks to a Subscriber
Process. Or, it could mean the name of two different message sent to a
publisher process.

\subsection{Dealer}

A dealer has \verb+N+ output ports. 
Messages sent to the input ports are round-robbined to
the output ports.

\begin{description}

\item \verb+{add_output,Pid}+\\
add Pid to the list of output ports.

\item \verb+{send,Message}+\\
  Send \verb+Message+ to one of the output ports.
  
  {\sl errors: There are no output ports}
\end{description}

\subsection{Router}

A router has an internal routing table which is a list of pairs of the form.
\verb+[{Tag,OutPort}]+. Message sent to the input port must have
a tag, these messages are sent to the appropriate output port.

\begin{description}
\item \verb+{add_route,Tag,Pid}+\\
  Adds a routing table entry \verb+{Tag, Pid}+ to the
  routing table. 

  {\sl errors: Tag already used}. 
  
\item \verb+{unroute,Tag}+\\
  Removes a routing table entry with \verb+Tag+ from the routing table.
  
\item \verb+{send,Tag,Msg}+\\
  Sends \verb+Msg+ to the process assocated with \verb+Tag+.
  
  {\sl errors: No process associated with Tag}
  
\end{description}

\subsection{Middle Man}

A middle man translates between two different messaging formats.  It has
two ports, call these \verb+a+ and \verb+b+.  Messages to port
\verb+a+ are in format \verb+one+ and messages to port \verb+b+ are in
format \verb+two+.

Messages arriving at port \verb+a+ should be converted from format
\verb+one+ to format \verb+two+ and sent to port \verb+b+ and {\sl
  vice versa.}

Here's a middle man that converts bwteen Metric and US meaasurements:

\begin{verbatim}

                 +-----+
                 |     |
      {km,3}   A |     |B  {miles,1.864}
  ------->-------+     +------->---------    
                 |     |
                 +-----+
\end{verbatim}

And in the opposite direction:

\begin{verbatim}

                 +-----+
                 |     |
    {km,3.218} A |     |B  {miles,2}
  -------<-------+     +-------<---------    
                 |     |
                 +-----+
\end{verbatim}


Examples: Convert JSON messages to XML messages, or Erlang terms.
Convert SAX events to XML terms.
 
\section{Router Code}

\VerbatimInput{router.erl}

The router assumes all messages are
are of the form: \verb+{do,Cmd,Epid}+
If the command works it does what it is supposed to do. If it fails
it sends a message to \verb+Epid+

\section{Publisher Code}

Here's a simple PUB-SUB publisher process. There is no error
handling.

\VerbatimInput{pubsub0.erl}

\end{document}


